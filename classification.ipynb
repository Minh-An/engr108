{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: Least squares classification \n",
    "\n",
    "## 14.1 Classification \n",
    "\n",
    "**Note on boolean values** Julia uses Boolean values `true` and `false`, converted to numbers 1 and 0. In VMLS, we use +1 and -1, so we must encode by `2*b-1` or via ternary operation `b ? 1 : -1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, -1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bool_2_signed(b) = 2*b-1\n",
    "bool_2_signed(true), bool_2_signed(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Int64}:\n",
       "  1\n",
       " -1\n",
       "  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = [true, false, true]\n",
    "bool_2_signed.(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix.** Calculating prediction errors and the confusion matrix, given a randomly generated set of data `y`and predictions `yhat` of length `N`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 24  27\n",
       " 23  26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using VMLS\n",
    "N = 100;\n",
    "y = rand(Bool, N); yhat = rand(Bool, N);\n",
    "\n",
    "Ntp(y,yhat) = sum((y .== true) .& (yhat .== true));\n",
    "Nfn(y,yhat) = sum((y .== true) .& (yhat .== false));\n",
    "Nfp(y,yhat) = sum((y .== false) .& (yhat .== true));\n",
    "Ntn(y,yhat) = sum((y .== false) .& (yhat .== false));\n",
    "\n",
    "error_rate(y,yhat) = avg(y .!= yhat) #  (Nfn(y,yhat) + Nfp(y,yhat)) / length(y);\n",
    "recall(y,yhat) = Ntp(y,yhat) / (Ntp(y,yhat) + Nfn(y,yhat))\n",
    "false_positive_rate(y,yhat) = Nfp(y,yhat) / (Nfp(y,yhat) + Ntn(y,yhat))\n",
    "\n",
    "confusion_matrix(y,yhat) = [Ntp(y,yhat) Nfn(y,yhat);\n",
    "                            Nfp(y,yhat) Ntn(y,yhat)];\n",
    "\n",
    "confusion_matrix(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.47058823529411764, 0.46938775510204084)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_rate(y,yhat), recall(y,yhat), false_positive_rate(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 Least squares classifier \n",
    "\n",
    "We can calculate $\\hat f(x) = sign(\\tilde f(x))$ using `ftilde(x) > 0` which returns a Boolean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iris flower classification.** The Iris data set contains 150 examples of 3 types of iris flowers (50 examples of each class). For each example, 4 features are provided. We write the following code to read in a dictionary containing 3, $50 \\times 4$ matrices `setosa, versicolor, virginica` and then computes a Boolean classifier that distinguishes *Iris Virginica* from the other 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bool[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -2.3905637266512034\n",
       " -0.09175216910134672\n",
       "  0.4055367711191063\n",
       "  0.007975822012794512\n",
       "  1.103558649867573"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using VMLS\n",
    "D = iris_data();\n",
    "iris = vcat(D[\"setosa\"], D[\"versicolor\"], D[\"virginica\"])\n",
    "y = [zeros(Bool, 100); ones(Bool, 50)]\n",
    "println(y)\n",
    "ysigned = bool_2_signed.(y)\n",
    "A = [ones(150) iris]\n",
    "theta = A \\ ysigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 46   4\n",
       "  7  93"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = A*theta .> 0\n",
    "C = confusion_matrix(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07333333333333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_rate(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3 Multi-class classifiers \n",
    "\n",
    "**Multi-class error rate and confusion matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "function k_confusion_matrix(y,yhat,K)\n",
    "    C = zeros(K,K)\n",
    "    for i=1:K\n",
    "        for j=1:K\n",
    "            C[i,j] = sum( (y .== i) .& (yhat .== j) )\n",
    "        end\n",
    "    end\n",
    "    return C\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Matrix{Float64}:\n",
       "  8.0   5.0  8.0  6.0\n",
       "  7.0   5.0  6.0  7.0\n",
       " 11.0  10.0  7.0  2.0\n",
       "  3.0   5.0  8.0  2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K = 4;\n",
    "y = rand(1:K, 100); yhat = rand(1:K, 100)\n",
    "\n",
    "C = k_confusion_matrix(y,yhat,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78, 0.78)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "error_rate(y,yhat), 1-sum(diag(C))/sum(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Least squares multi-class classifier** A $K$-class classifier (with regression model) can be expressed as \n",
    "\n",
    "\\begin{align}\n",
    "\\hat f(x) = \\argmax_{k=1,\\dots,K} \\tilde f_k(x),\n",
    "\\end{align}\n",
    "\n",
    "where $\\tilde f_k(x) = x^T \\theta_k.$. The $n$-vectors $\\theta_1,\\dots,\\theta_K$ are the coefficients or parameters in the model. We can express this in matrix-vector notation as \n",
    "\n",
    "\\begin{align}\n",
    "\\hat f(x) = \\argmax(x^T \\Theta),\n",
    "\\end{align}\n",
    "\n",
    "where $\\Theta = [\\theta_1,\\dots,\\theta_K]$ is the $n \\times K$ matrix of model coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of x'Theta is 1xK\n",
    "# for N examples X, X'Theta gives NxK matrix \n",
    "\n",
    "# define function that will return N-vector \n",
    "# calculating fhat for all N examples \n",
    "# i.e. taking the argmax of each row in the NxK matrix\n",
    "\n",
    "row_argmax(m) = [argmax(m[i, :]) for i=1:size(m,1)];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix least squares.** Least squares to find coefficient matrix $\\Theta$ for a multi-class classifier with $n$ features and $K$ classes, from a data set of $N$ examples. We will assume data $X$ is given as $n \\times N$ matrix and the classes of the examples will be given as $N$-vector $y^{cl}$ with entries $\\in \\{1,\\dots,K\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least squares objective cam be expressed as a matrix norm squared, \n",
    "\n",
    "\\begin{align}\n",
    "||X^T \\Theta - Y||^2\n",
    "\\end{align}\n",
    "\n",
    "where $Y$ is the $N \\times K$ matrix with \n",
    "\n",
    "\\begin{align}\n",
    "Y_{ij} = \\begin{cases}\n",
    "            1 & y_i^{cl} = j\\\\\n",
    "            -1 & y_i^{cl} \\not =  j\n",
    "         \\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "The least squares solution is given by $\\hat \\Theta = (X^T)^{\\dagger} Y $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×4 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  1.0\n",
       " 1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0\n",
       " 0.0  0.0  0.0  1.0\n",
       " 1.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function returns a N x K matrix Y \n",
    "# with one hot encoding mentioned above\n",
    "# (0 for false, 1 for true)\n",
    "function one_hot(y, K)\n",
    "    N = length(y)\n",
    "    Y = zeros(N,K)\n",
    "    for j=1:K\n",
    "        Y[findall(y .== j), j] .= 1\n",
    "    end\n",
    "    return Y\n",
    "end;\n",
    "\n",
    "# example \n",
    "K = 4\n",
    "ycl = rand(1:K,6)\n",
    "Y = one_hot(ycl, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×4 Matrix{Float64}:\n",
       " -1.0  -1.0  -1.0   1.0\n",
       "  1.0  -1.0  -1.0  -1.0\n",
       " -1.0  -1.0  -1.0   1.0\n",
       " -1.0  -1.0  -1.0   1.0\n",
       "  1.0  -1.0  -1.0  -1.0\n",
       "  1.0  -1.0  -1.0  -1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our function to convert to -1/1 scale\n",
    "bool_2_signed.(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for matrix least squares \n",
    "# multi-class classfier \n",
    "function ls_multiclass(X, y, K)\n",
    "    n, N = size(X)\n",
    "    Y = bool_2_signed.(one_hot(y, K))\n",
    "    Theta = X' \\ Y \n",
    "    yhat = row_argmax(X'*Theta)\n",
    "    return Theta, yhat\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iris flower multi-class classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "D = iris_data();\n",
    "setosa = D[\"setosa\"];\n",
    "versicolor = D[\"versicolor\"];\n",
    "virginica = D[\"virginica\"];\n",
    "\n",
    "# pick 3 random perms of 1-50 (one for each class)\n",
    "idx1 = Random.randperm(50);\n",
    "idx2 = Random.randperm(50);\n",
    "idx3 = Random.randperm(50);\n",
    "\n",
    "# training set is 40 randomly picked examples per class \n",
    "Xtrain =  [ setosa[     idx1[1:40],:];\n",
    "            versicolor[ idx2[1:40],:];\n",
    "            virginica[  idx3[1:40],:]   \n",
    "          ]';\n",
    "# add a new constant feature \n",
    "Xtrain = [ones(1,120); Xtrain];\n",
    "#ylabels \n",
    "ytrain = [ones(40); 2*ones(40); 3*ones(40)];\n",
    "\n",
    "# test set is all other examples not picked for training\n",
    "Xtest =   [ setosa[     idx1[41:end],:];\n",
    "            versicolor[ idx2[41:end],:];\n",
    "            virginica[  idx3[41:end],:]   \n",
    "          ]';\n",
    "Xtest = [ones(1,30); Xtest];\n",
    "ytest = [ones(10); 2*ones(10); 3*ones(10)];\n",
    "\n",
    "Theta, yhat = ls_multiclass(Xtrain, ytrain, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×3 Matrix{Float64}:\n",
       " -0.810683   2.43811    -2.62743\n",
       "  0.125552  -0.0473458  -0.0782058\n",
       "  0.499109  -0.941416    0.442307\n",
       " -0.41321    0.346798    0.0664124\n",
       " -0.187698  -0.759335    0.947033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 40.0   0.0   0.0\n",
       "  0.0  29.0  11.0\n",
       "  0.0   4.0  36.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ctrain = k_confusion_matrix(ytrain, yhat, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 10.0  0.0  0.0\n",
       "  0.0  7.0  3.0\n",
       "  0.0  2.0  8.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat_test = row_argmax(Xtest'*Theta)\n",
    "Ctest = k_confusion_matrix(ytest, yhat_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_train = error_rate(ytrain, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_test = error_rate(ytest, yhat_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
